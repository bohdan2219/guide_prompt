# Nollakehottaminen
Nykyiset suuret LLM:t, kuten GPT-3, on viritetty seuraamaan ohjeita ja niitä on koulutettu suurilla datamäärillä, joten ne pystyvät suorittamaan joitakin tehtäviä "nollaoppimisen" avulla.

Kokeilimme muutamia nollaoppimisen esimerkkejä edellisessä osiossa. Tässä yksi käyttämistämme esimerkeistä:

*Kehote:*
```
Luokittele teksti neutraaliksi, negatiiviseksi tai positiiviseksi. 

Teksti: Lomamatka oli ihan OK. 
Luokitus:
```

*Tulos:*
```
Neutraali
```

Huomaa, että yllä olevassa kehotteessa emme antaneet mallille mitään esimerkkejä teksteistä luokittelujen kanssa. LLM ymmärtää jo "tilanteen" – tässä on kyse nollaoppimisen kyvyistä.

Ohjeiden avulla virittämisen on osoitettu parantavan nollaoppimista [Wei ym. (2022)](https://arxiv.org/pdf/2109.01652.pdf). Ohjeiden avulla virittäminen on mallien hienosäätämisen käsite, jossa tiettyä tietojoukkoa on kuvailtu mallille, ja sen kanssa toimimiselle on annettu ohjeistus. Lisäksi, [RLHF](https://arxiv.org/abs/1706.03741) (reinforcement learning from human feedback, vahvistusoppiminen ihmispalautteesta) on otettu käyttöön ohjeiden virittämisen skaalaamiseksi, jolloin malli sovitetaan paremmin ihmisten mieltymyksiin. Tämä viimeaikainen kehitys tekee malleista, kuten ChatGPT, tehokkaita. Käsittelemme kaikkia näitä lähestymistapoja ja menetelmiä tulevissa osioissa.

Kun nollaoppimiskehote ei tuota haluttua tulosta, on suositeltavaa antaa demonstraatioita tai esimerkkejä kehotteessa, mikä johtaa vähäisen ohjauksen kehotteiden hyödyntämiseen. Seuraavassa osiossa esittelemme vähäisen ohjauksen kehottamista.